<!--

author: Moritz Riemann, Gregor Große-Bölting
email:  ggb@informatik.uni-kiel.de
version: 0.1
language: en
narrator: UK English Female

\-->

# Heinrich Blüchers Nachlass

**Dozierende:**

* Moritz Riemann (riemann@philsem.uni-kiel.de)
* Gregor Große-Bölting (ggb@informatik.uni-kiel.de)

**Zeit und Raum:** Di 16:15 - 17:45, CAP4 - R.13.1304a

**Inhalt:**

* Interdisziplinäres Arbeiten: Philosophie- und Informatikstudierende arbeiten zusammen und gewinnen Einblick in das andere Fach
* Einblick in die Digital Humanities und grundlegendes Verständnis digitaler Methoden geisteswissenschaftlicher Arbeit
* Arbeit mit X-Technologien, wie XML TEI, ODD, XSLT und RDF
* Praktische Fähigkeiten im Umgang mit Forschungsdaten und im kollaborativen Arbeiten
* Digitale Analyse- und Visualisierungsmethoden für geisteswissenschaftliche Fragestellungen
* Erforschung angemessener Formen interdisziplinär-digitaler Wissenschaft und Universität
* Reflexion der eigenen Fachkultur und der Methoden der Informatik bzw. Digital Humanities

**Literatur:**

* Blücher, H. (1952). Why and How We Study Philosophy. https://www.bard.edu/library/pdfs/bluecher/Why%20and%20How%20We%20Study%20Philosophy%20-%20Bl%C3%BCcher%20Archives%20PDF.pdf
* Kapitel 1 und 2 in: Jannidis, F., Kohle, H., & Rehbein, M. (2017). Digital Humanities. J.B. Metzler. https://doi.org/10.1007/978-3-476-05446-3

**Link zu OLAT:** https://lms.uni-kiel.de/auth/RepositoryEntry/5362057253/CourseNode/108032371510857

## Organisatorisches

### Regierungserklärung

1. Diese Veranstaltung ist ein Experiment: Wir setzen neue Methoden und Software ein. Seid also nachsichtig mit uns und mit euch selbst, wenn mal etwas nicht funktioniert wie geplant. Lasst uns zeitnah wissen, wenn ihr Probleme habt, dann findet sich für alles eine Lösung!
2. Ihr dürft (und sollt) gerne eigene Tools und Ideen einbringen! Der Seminarplan ist auch offen für Eure Vorschläge.
3. Interdisziplinarität lebt von wechselseitiger Verständlichkeit: Redet mit uns und mit Euren Mitstudierenden, wenn ihr Dinge nicht versteht oder Hilfe braucht.
4. Der Seminarplan ist "im Fluss".

### Semesterplan

| Datum | Thema/Inhalt |
|-------|--------------|
| 24.10. | Begrüßung, Einführung in das Thema, Überblick über das Semester |
| 31.10. | FEIERTAG |
| 07.11. | **Distant Reading** |
| 14.11. | Voyant: Tool-Präsentation und vers. Werkzeuge |
| 21.11. | Möglichkeiten und Einschränkungen |
| 28.11. | **Deep Reading** |
| 05.12. | TEI Publisher: Tool-Präsentation, TEI-Grundlagen |
| 12.12. | FÄLLT AUS |
| 19.12. | Ergebnisse; Unterschiede Deep Reading und Annotationen analog/digital |
| 09.01. | *Digitale* Forschungsfragen |
| 16.01. |  **Close Reading** |
| 23.01. | Tool-Präsentation |
| 30.01. | tba / Referate? |
| 06.02. | DOPPELSITZUNG (16 - 20 Uhr): Präsentation und Evaluation |

### Prüfungsleistung

**Für Informatiker_innen:** 

Details folgen.

* Werkstattbericht über einen der drei Teile (Distant/Deep/Close Reading), Details folgen (20%)
* Peer Review (20%)
* Poster und Posterpräsentation (30%)
* Ausarbeitung (30%)

**Für Philosoph_innen:**

Jede der Prüfungsformen beinhaltet die gemeinsame Präsentation in einer Kleingruppe am Ende des Semesters.

* Referate: bitte frühzeitig melden!
* Essay
* Hausarbeit
* mdl. Prüfung

---

Mögliche Referatsthemen:

* Einführung ins Denken Heinrich Blüchers
* Leuchtturmprojekte DH (Philosophie)
* Blücher, Arendt, Jaspers: Eine intellektuelle Freundschaft
* Chancen/Grenzen Deep Reading analog/digital
* ...

## Sitzung am 24.10.

### "Speed Dating"

Sprecht mit der Person, die euch gegenübersitzt, zwei Minuten über die folgenden Fragen:

1. Warum studiert Ihr Eure Disziplin?
2. Was bewundert Ihr an der jeweils anderen Disziplin?

Wenn das Signal gegeben wird, rücken diejenigen, die mit dem Gesicht zum Eingang/Front sitzen, einen Platz nach links.

Diejenigen die außen sitzen wechseln die Reihe und füllen den leeren Platz in der nächsten Reihe auf usw.

### Wer ist Heinrich Blücher?

Hannah Arendt über ihren Mann Heinrich Blücher in einem Brief an Karl Jaspers:

> Mein Mann heißt Heinrich Blücher -- schriftliche Beschreibung unmöglich. Er hat während des Krieges hier teils für die Armee, teils für Universitäten und teils als broadcaster gearbeitet auf Grund seiner militärwissenschaftlichen Kenntnisse. Mit Beendigung des Krieges ist er aus all diesen mehr oder minder offiziellen Dingen herausgegangen und arbeitet augenblicklich im economic research für Privatfirmen. Er stammt aus einer Berliner Arbeiterfamilie, hat in Berlin Geschichte unter Delbrück studiert, war dann Redakteur eines Nachrichtendienstes und hat sich verschiedentlich politisch betätigt. (Hannah Arendt an Karl Japsers, 29. Januar 1946, Arendt-Jaspers Briefe, S. 65)

<iframe width="100%" height="600px" frameborder="0" allowfullscreen allow="geolocation" src="https://umap.openstreetmap.fr/en/map/hannah-arendts-fluchtroute-von-berlin-nach-new-yor_977287?scaleControl=false&miniMap=false&scrollWheelZoom=false&zoomControl=true&editMode=disabled&moreControl=true&searchControl=null&tilelayersControl=null&embedControl=null&datalayersControl=true&onLoadPanel=undefined&captionBar=false&captionMenus=true"></iframe><p><a href="https://umap.openstreetmap.fr/en/map/hannah-arendts-fluchtroute-von-berlin-nach-new-yor_977287?scaleControl=false&miniMap=false&scrollWheelZoom=true&zoomControl=true&editMode=disabled&moreControl=true&searchControl=null&tilelayersControl=null&embedControl=null&datalayersControl=true&onLoadPanel=undefined&captionBar=false&captionMenus=true">See full screen</a></p>

### Why and How We Study Philosophy

> In philosophy we have no right to throw out one erroneous answer if that answer has quality (human experience), and since in philosophy we are concerned with the idea itself (for example: philosophy is concerned with the idea of God, religion with the existence of God) and how it was possible for man to arrive at that idea or answer at all, we have always to look and to inquire again. So in discussing the situation we now find ourselves in and how it came about and man's changed position in the world, we have to look back at how man lived up to 1800 and have to ask: How was it possible and how did it happen that man believed in God almost up to 1800 and then suddenly stopped--replacing this dropped belief with a merely negative belief that God did not exist. (Heinrich Blücher: Why and How We Study Philosophy)

### Zur nächsten Sitzung

* Erste Vorlesung (S. 1 - 5) in: Heinrich Blücher. Why and How We Study Philosophy. https://www.bard.edu/library/pdfs/bluecher/Why%20and%20How%20We%20Study%20Philosophy%20-%20Bl%C3%BCcher%20Archives%20PDF.pdf 
* Kapitel 1 und 2 in: Jannidis, F., Kohle, H., & Rehbein, M. (2017). Digital Humanities. J.B. Metzler. https://doi.org/10.1007/978-3-476-05446-3 (über die UB digital verfügbar!)
* Moretti, F. (2000). Conjectures on World Literature. New Left Review, 1, 54–68. https://newleftreview.org/issues/ii1/articles/franco-moretti-conjectures-on-world-literature

## Sitzung am 07.11.

Diese Sitzung ist der Methode des *Distant Reading* gewidmet. Dazu werden zunächst drei verschiedene Fallstudien betrachtet, die alle unterschiedliche Bereiche der Philosophie mit verschiedenen Zugängen "aus der Ferne" zu ergründen versuchen. Anschließend erfolgt eine Diskussion des Papers, in dem die Begriffsprägung *Distant Reading* durch den italienischen Literaturwissenschaftler Franco Moretti erfolgt ist.

Weiterführende Literatur und Ressourcen:

* Ted Underwood: A Genealogy of Distant Reading. In: digital humanities quarterly. Vol. 11, No. 2, 2017
* Kathryn Schulz: What is Distant Reading? In: New York Times, 24. Juni 2011 (https://www.nytimes.com/2011/06/26/books/review/the-mechanic-muse-what-is-distant-reading.html)
* Zwei Besprechungen von [Morettis Buch](https://www.wallstein-verlag.de/9783835390768-distant-reading.html), die zu sehr unterschiedlichen Schlüssen kommen: https://literaturkritik.de/id/22506 und https://literaturkritik.de/id/22507

### Fallstudie 1: Nietzsche

> The basic idea is extremely flat-footed and simple-minded: I come up with a list of concepts or constructs that, based on my reading of Nietzsche over the years as well as my familiarity with the secondary literature, are probably important for him. Then I associate each concept or construct with the German words (actually word stems) that he uses to refer to or express it. For instance, the concept of  virtue  is associated with anything beginning with ‘tugend’. Some concepts are associated with only one word stem, others with multiple. [...] Once I’m satisfied with the list of word stem(s) associated with a given concept, I then run an algorithm over the entire corpus to find out which passages contain which concepts. I initially did this all by hand via www.nietzschesource.org, which is an outstanding resource. It took months. But then I met a computer scientist by the name of Marc Cheong who figured out how to do it automatically in the course of about a minute. (https://www.3-16am.co.uk/articles/nietzsche-and-virtue?c=end-times-series)

In einem [ausführlichen Blog-Post](http://www.alfanophilosophy.com/blog/2017/7/25/a-semantic-network-approach-to-the-history-of-philosophy-or-what-does-nietzsche-talk-about-when-he-talks-about-emotion) erläutert Mark Alfano, wie er das Gesamtwerk von Friedrich Nietzsche anhand einiger vorausgewählter Konzepte codiert und die Ergebnisse als Netzwerk visualisiert hat. Zudem ist durch verschiedene Visualisierungen pro Werk die zeitliche Entwicklung von Konzepten im Schreiben Nietzsches nachvollziehbar.

Besonders interessant sind dabei insbesondere der Methodenteil zu Anfang und einige der Schlüsse, die Alfano aus seiner Analyse zieht (werden *ressentiment* und *Wille zur Macht* möglicherweise nur deswegen mit Nietzsche verbunden, weil sie im Text durchgehend kursiviert sind?).

![semantic map of Nietzsche’s overall moral psychology](https://images.squarespace-cdn.com/content/v1/53ee4729e4b0b2ea897b1530/1500971863304-QZ2Y1WIBY6U0DW8BR63T/image-asset.png?format=2500w "Semantic map of Nietzsche’s overall moral psychology")

### Fallstudie 2: Ancient Philosophers: A First Statistical Survey

> Until recently, ancient philosophy was studied by genuine philosophers concerned with the history of ideas, or by philologists trying to provide editions and translations of documents handed down by the manuscript tradition. Philosophy as a social movement in the ancient world, the daily professional activity of the well-established figure of the philosopher, or the impact of philosophical ideas on the Greek and Roman societies have not produced an extensive literature. While some intuitive convictions are commonly held on these matters, no general inquiry has ever been carried out, and no statistical value of any kind is currently available. Asking specialists how many philosophers are known through our documents would  probably produce very disparate answers. Standard books on the history of philosophy would suggest a few hundred, some more specialized  dictionaries or encyclopedias perhaps some six or seven hundred, but our own accounts have identified nearly 3000 names, not all of whom are  necessarily full-fledged philosophers, but at least important witnesses of ancient philosophical tradition

Das Projekt versucht anhand der Zeugnisse von über knapp 3.000 Philosoph:innen einen Überblick über die antike Philosophie zu geben. Dafür werden verschiedene Merkmale wie Geschlecht, Schulzugehörigkeit und politisches Engagement in Betracht gezogen.

Das zugehörige Paper gibt es hier: https://doi.org/10.1002/9781118609187.ch2 oder im Materialverzeichnis (OLAT).

### Fallstudie 3: Wittgenstein und Wittgensteinianer

> Our aim is that of focusing on works about Wittgenstein, rather than on Wittgenstein’s own philosophical work. There are two reasons why our work can be considered a case of distant reading. First, we take a certain ‘distance’ from Wittgenstein, our object of investigation. Second, we do not closely read the texts we investigate, but rather we attempt to reconstruct some of their aggregate properties. Methodologically, this article lies within the sociology of philosophy, based on the analysis of bibliographical data (McKenzie 1986, Santoro and Gallelli 2016, Gerli and Santoro 2018).

[Diese Studie](https://journals.openedition.org/jihi/317) untersucht nicht die Arbeiten des Philosophen Ludwig Wittgenstein, sondern analysiert die Bücher, Aufsätze und Autoren, die sich mit seinem Werk auseinandersetzen.

### Franco Moretti: "Conjectures on World Literature"

> Many people have read more and better than I have, of course, but still, we are talking of hundreds of languages and literatures here. Reading ‘more’ seems hardly to be the solution. Especially because we’ve just started rediscovering what Margaret Cohen calls the ‘great unread’. ‘I work on West European narrative, etc. ...’ Not really, I work on its canonical fraction, which is not even one per cent of published literature. And again, some people have read more, but the point is that there are thirty thousand nineteenth-century British novels out there, forty, fifty, sixty thousand—no one really knows, no one has read them, no one ever will. And then there are French novels, Chinese, Argentinian, American ...
>
> Reading ‘more’ is always a good thing, but not the solution.

https://newleftreview.org/issues/ii1/articles/franco-moretti-conjectures-on-world-literature

### Zur nächsten Sitzung

* Setzt euch mit einer der oben angegebenen Fallstudien auseinander ODER sucht selbst nach einem Anwendungsfall von *Distant Reading* in der Philosophie: Welche Vorarbeiten und Vorannahmen werden durch die Autor:innen geleistet/angenommen?
* Zweite Vorlesung (S. 6 - 11) in: Heinrich Blücher. Why and How We Study Philosophy. https://www.bard.edu/library/pdfs/bluecher/Why%20and%20How%20We%20Study%20Philosophy%20-%20Bl%C3%BCcher%20Archives%20PDF.pdf

## Sitzung am 14.11.

Diese Sitzung geht es darum zu verstehen, wie Verfahren zur automatischen Textverarbeitung funktionieren und welche Abstriche dabei in Kauf genommen werden. Außerdem beschäftigen wir uns mit Voyant Tools, einer Software zur automatischen Textanalyse.

Weiterführende Literatur und Ressourcen:

* In OLAT finden sich Vorlesungen von Heinrich Blücher zum Herumprobieren.
* Für alle, die sich dem Thema programmierend nähern möchten: https://pythonhumanities.com/python-for-dh-course/ 
* Weitere Texte für eigene Versuche finden sich bspw. im [Deutschen Textarchiv](https://www.deutschestextarchiv.de), z. B. Immanuel Kants ["Beantwortung der Frage: Was ist Aufklärung?"](https://www.deutschestextarchiv.de/book/show/16167)


### Grundlagen der automatischen Textverarbeitung

Texte werden im Computer als eine Zeichenkette oder eine Folge von Zeichen (*string*) repräsentiert. Dieser Ansatz ermöglicht es, Texte in digitaler Form zu speichern, zu verarbeiten und anzuzeigen. Jeder Buchstabe, Satzzeichen, Zahl oder Sonderzeichen, die in einem Text vorkommen, wird dabei durch eine spezielle Codierung abgebildet.

Eine der häufigsten Codierungen für die Repräsentation von Texten ist die ASCII-Codierung (American Standard Code for Information Interchange). Hierbei werden Buchstaben, Zahlen, Sonderzeichen und Steuerzeichen durch jeweils 7 oder 8 Bits dargestellt. Das bedeutet, dass jedem Zeichen eine eindeutige Binärsequenz zugeordnet wird, was es dem Computer ermöglicht, die Zeichen korrekt zu interpretieren und anzuzeigen.

![ASCII-Tabelle aus MIL-STD-188-100 (1972)](img/USASCII_code_chart.png "ASCII-Tabelle aus MIL-STD-188-100 (1972)")

**Beispiel:** Der String *Hallo* würde in ASCII als `01001000 01100001 01101100 01101100 01101111 00100001` repräsentiert werden. 

Mit der Zeit wurden weitere (und komplexere) Codierungsstandards entwickelt, um Zeichen aus verschiedenen Sprachen und Schriften darstellen zu können. Zum Beispiel ermöglicht Unicode die Darstellung einer Vielzahl von Schriftsystemen, darunter auch komplexere Schriften wie chinesische, arabische und indische Schriften. Unicode erweitert die ASCII-Codierung und weist jedem Zeichen eine eindeutige Nummer zu, wodurch es möglich wird, Texte in verschiedenen Sprachen und Schriftsystemen auf Computern korrekt wiederzugeben.

**Beispiel:** Angenommen, wir haben den Text "こんにちは" in der japanischen Sprache, was "Konnichiwa" auf Englisch bedeutet. Jedes Zeichen in diesem Text wird gemäß der Unicode-Codierung einer spezifischen Nummer zugeordnet, die dann in binärer Form im Computer gespeichert wird. Für das Beispiel "こんにちは" würden die einzelnen Zeichen gemäß Unicode wie folgt dargestellt werden:

* "こ" entspricht der Unicode-Nummer U+3053
* "ん" entspricht der Unicode-Nummer U+3093
* "に" entspricht der Unicode-Nummer U+306B
* "ち" entspricht der Unicode-Nummer U+3061
* "は" entspricht der Unicode-Nummer U+306F

Die Repräsentation von Texten als Zeichenketten im Computer bildet die Grundlage für Textverarbeitungsanwendungen, Suchmaschinen, Datenbanken und viele weitere digitale Anwendungen im Bereich der Geisteswissenschaften. Sie ermöglicht die Speicherung und Analyse von Texten in digitaler Form, was die Arbeit mit großen Textmengen und die Durchführung komplexer Textanalysen erleichtert.

#### Dokument und Korpus

Ein *Dokument* repräsentiert eine einzelne Einheit von Text, die als Ganzes betrachtet wird. Es kann sich dabei um einen Artikel, einen Blogbeitrag, eine E-Mail, einen Abschnitt eines Buches oder eine andere Texteinheit handeln. In der Textanalyse wird ein Dokument oft als die kleinste verarbeitbare Einheit betrachtet. Analysen, wie die Extraktion von Schlüsselwörtern, Sentimentanalyse oder Themenmodellierung, können auf der Ebene einzelner Dokumente durchgeführt werden.

Ein *Korpus* bezeichnet eine Sammlung von Textdokumenten. Es ist eine größere Menge von Texten, die für eine bestimmte Analyse oder Forschungszwecke zusammengestellt wurde. Korpora dienen als Grundlage für umfassendere Textanalysen. Sie ermöglichen die Extraktion von Mustern, Trends und Informationen auf der Ebene der gesamten Textsammlung. Korpora können aus Texten zu einem bestimmten Thema, aus einer bestimmten Quelle oder aus verschiedenen Genres bestehen und werden in verschiedenen Bereichen wie maschinelles Lernen, Sprachverarbeitung und Textlinguistik verwendet.

Die Grenzen zwischen *Dokument* und *Korpus* sind nicht zwingend fixiert: Wir können Blüchers Vorlesung "Why and How We Study Philosophy" als ein Dokument *oder* als einen Korpus (bestehend aus einer Reihe von Dokumenten, den Vorlesungen) betrachten. 

#### Stopwords

**Beispiel:** Wir betrachten den folgenden Textausschnitt von Heinrich Blücher: 

> In philosophy we have no right to throw out one erroneous answer if that answer has quality (human experience), and since in philosophy we are concerned with the idea itself (for example: philosophy is concerned with the idea of God, religion with the existence of God) and how it was possible for man to arrive at that idea or answer at all, we have always to look and to inquire again. So in discussing the situation we now find ourselves in and how it came about and man's changed position in the world, we have to look back at how man lived up to 1800 and have to ask: How was it possible and how did it happen that man believed in God almost up to 1800 and then suddenly stopped--replacing this dropped belief with a merely negative belief that God did not exist. (Heinrich Blücher: Why and How We Study Philosophy)

Durch die Entfernung von *stopwords* wird aus dem Ausgangs- der folgende Text:

> philosophy throw erroneous answer answer quality (human experience), philosophy concerned idea philosophy concerned idea God, religion existence God) man arrive idea answer inquire discussing situation man's changed position man lived 1800 happen man believed God 1800 suddenly stopped--replacing dropped belief negative belief God exist.

Die folgenden *stopwords* wurden in diesem Falle entfernt:

> in we have no right to out one if that has and since are with the itself for example is of how it was possible at or all always look again so now find ourselves came about world back up ask did almost then this a merely not

---

*Stopwords* sind häufig vorkommende Wörter in einer Sprache, die jedoch wenig semantische Bedeutung tragen. Beispiele für Stopwords im Englischen sind "and", "the", "is", usw. In der automatischen Textverarbeitung werden diese Wörter oft als Rauschen betrachtet, da sie wenig zur inhaltlichen Analyse beitragen, aber viel Speicherplatz und Rechenzeit in Anspruch nehmen können.

Die Funktion von *stopword removal* besteht darin, diese häufigen Wörter aus einem Text zu entfernen, um die Relevanz der verbleibenden Wörter zu erhöhen. Dieser Prozess kann durch Filtern einer vordefinierten Liste von Stopwords oder durch Analyse der Häufigkeit von Wörtern im Kontext eines spezifischen Textkorpus erfolgen. Durch das Entfernen von Stopwords können Textanalysen präziser werden, da die Betonung auf bedeutungsvolleren Wörtern liegt. Dies ist besonders nützlich in den digitalen Geisteswissenschaften, wo die inhaltliche Interpretation von Texten im Vordergrund steht und Rauschen in Form von häufigen, aber wenig aussagekräftigen Wörtern vermieden werden soll.

Fragen:

1. Wer legt fest, was ein *stopword* ist? Welche Konsequenzen hat das?
2. Was verbessert *stopword removal*? Was wird dadurch schlechter?

#### Stemming und lemmatization

**Beispiel:** Wir betrachten (erneut) den folgenden Textausschnitt von Heinrich Blücher: 

> In philosophy we have no right to throw out one erroneous answer if that answer has quality (human experience), and since in philosophy we are concerned with the idea itself (for example: philosophy is concerned with the idea of God, religion with the existence of God) and how it was possible for man to arrive at that idea or answer at all, we have always to look and to inquire again. So in discussing the situation we now find ourselves in and how it came about and man's changed position in the world, we have to look back at how man lived up to 1800 and have to ask: How was it possible and how did it happen that man believed in God almost up to 1800 and then suddenly stopped--replacing this dropped belief with a merely negative belief that God did not exist. (Heinrich Blücher: Why and How We Study Philosophy)

Durch *stemming* wird daraus:

> In philosophi we have no right to throw out one erron answer if that answer ha qualiti ( human experi ), and sinc in philosophi we are concern with the idea itself ( for exampl : philosophi is concern with the idea of God , religion with the exist of God ) and how it wa possibl for man to arriv at that idea or answer at all , we have alway to look and to inquir again . So in discuss the situat we now find ourselv in and how it came about and man ' s chang posit in the world , we have to look back at how man live up to 1800 and have to ask : How wa it possibl and how did it happen that man believ in God almost up to 1800 and then suddenli stop -- replac thi drop belief with a mere neg belief that God did not exist .

Durch *lemmatization*:

>  in philosophy we have no right to throw out one erroneous answer if that answer have quality ( human experience ) , and since in philosophy we be concern with the idea itself ( for example : philosophy be concern with the idea of God , religion with the existence of God ) and how it be possible for man to arrive at that idea or answer at all , we have always to look and to inquire again . so in discuss the situation we now find ourselves in and how it come about and man 's change position in the world , we have to look back at how man live up to 1800 and have to ask : how be it possible and how do it happen that man believe in God almost up to 1800 and then suddenly stop -- replace this drop belief with a merely negative belief that God do not exist .

--- 

*Stemming* und *Lemmatisierung* sind zwei Techniken der Textnormalisierung in der linguistischen Verarbeitung von Texten. Beide Methoden zielen darauf ab, Wörter auf ihre Grundformen zu reduzieren, um Textanalysen zu verbessern.

*Stemming* ist ein Verfahren, bei dem Wörter auf ihren sogenannten Stamm (oder Wortstamm) reduziert werden, indem übliche Suffixe entfernt werden. Dies bedeutet, dass verschiedene grammatische Formen eines Wortes auf denselben Stamm zurückgeführt werden, unabhängig von ihrer spezifischen Flexion. Das Wort "running" wird durch Stemming auf den Stamm "run" reduziert.

Im Gegensatz dazu versucht die *Lemmatisierung*, Wörter auf ihre lexikalische Grundform (Lemma) zurückzuführen. Dabei werden nicht nur grammatische Formen, sondern auch die semantische Bedeutung berücksichtigt. Das Ergebnis ist ein echtes Wort (Lemma), das im Wörterbuch zu finden ist. Das Wort "better" wird durch Lemmatisierung auf die Lemme "good" reduziert.

In beiden Fällen helfen *Stemming* und *Lemmatisierung* dabei, die Vielfalt der Formen eines Wortes zu reduzieren, was besonders in der Textanalyse und maschinellen Verarbeitung natürlicher Sprache (NLP) nützlich ist: Es erleichtert die Vergleichbarkeit von Wörtern und verbessert die Extraktion von Schlüsselinformationen aus Texten. Stemming ist dabei weniger aufwendig, während Lemmatisierung in der Regel präzisere Ergebnisse liefert.

#### Bag-of-words und n-Grame

**Beispiel:** Wir betrachten (schon wieder...) den folgenden Textausschnitt von Heinrich Blücher: 

> In philosophy we have no right to throw out one erroneous answer if that answer has quality (human experience), and since in philosophy we are concerned with the idea itself (for example: philosophy is concerned with the idea of God, religion with the existence of God) and how it was possible for man to arrive at that idea or answer at all, we have always to look and to inquire again. So in discussing the situation we now find ourselves in and how it came about and man's changed position in the world, we have to look back at how man lived up to 1800 and have to ask: How was it possible and how did it happen that man believed in God almost up to 1800 and then suddenly stopped--replacing this dropped belief with a merely negative belief that God did not exist. (Heinrich Blücher: Why and How We Study Philosophy)

Daraus wird als *bag-of-words*:

| to | and | in | we | have | how | the | be | it | that | ... |
|----|-----|----|----|------|-----|-----|----|----|------|-----|
| 8  |  8  | 6  | 5  | 5    | 5   | 5   | 4  | 4  | 4    | ... |

Als Darstellung mit *2-Gramm*en:

| we have | and how | with the | up to | how it | in philosophy | ... |
|---------|---------|----------|-------|--------|---------------|-----|
| 3       | 3       | 3        | 2     | 2      | 2             | ... |

---

*Bag-of-Words* ist eine Art der Textrepräsentation in der maschinellen Textverarbeitung. Bei dieser Methode wird ein Text als eine "Tasche" (englisch: bag) von Wörtern betrachtet, wobei die Reihenfolge der Wörter ignoriert wird, und nur die Häufigkeit der Wörter im Text berücksichtigt wird. Das bedeutet, dass die Information über die Wortreihenfolge im Text verloren geht, und der Fokus allein auf dem Auftreten der Wörter liegt. Diese Darstellung wird häufig für Textklassifikation, Clustering und andere Textanalysen verwendet.

Ein *n-Gramm* ist in der Sprachverarbeitung eine aufeinanderfolgende Sequenz von n Elementen (normalerweise Wörtern), die aus einem Text extrahiert werden. Diese Elemente können Buchstaben, Silben, Wörter oder sogar ganze Sätze sein, abhängig vom Kontext der Analyse. N steht dabei für die Anzahl der Elemente in einem n-Gramm.

#### Häufigkeit und Dichte

**Beispiel:** Wir betrachten (schon wieder...) den folgenden Textausschnitt von Heinrich Blücher: 

> In philosophy we have no right to throw out one erroneous answer if that answer has quality (human experience), and since in philosophy we are concerned with the idea itself (for example: philosophy is concerned with the idea of God, religion with the existence of God) and how it was possible for man to arrive at that idea or answer at all, we have always to look and to inquire again. So in discussing the situation we now find ourselves in and how it came about and man's changed position in the world, we have to look back at how man lived up to 1800 and have to ask: How was it possible and how did it happen that man believed in God almost up to 1800 and then suddenly stopped--replacing this dropped belief with a merely negative belief that God did not exist. (Heinrich Blücher: Why and How We Study Philosophy)

Das Wort *god* hat eine Worthäufigkeit `= 4`, die Dichte des Texts beträgt `0,545`. 

--- 

Die *Worthäufigkeit* (Term Frequency, TF) misst, wie oft ein bestimmtes Wort in einem Dokument erscheint, im Verhältnis zur Gesamtanzahl der Wörter in diesem Dokument. Ein höherer TF-Wert deutet darauf hin, dass das Wort im Dokument häufig vorkommt und kann als Indikator für die Relevanz des Worts im Kontext des spezifischen Dokuments dienen. Die TF-Metrik ist grundlegend für Bag-of-Words-Modelle und Textanalyseanwendungen.

Die *Wortschatzdichte* (Vocabulary Density) bezieht sich auf das Verhältnis der einzigartigen Wörter zur Gesamtanzahl der Wörter in einem Dokument. Ein Dokument mit einer höheren Wortschatzdichte enthält mehr unterschiedliche Wörter und zeigt somit eine größere sprachliche Vielfalt. Dies kann auf die inhaltliche Komplexität oder Spezifität eines Textes hinweisen und ist in der Textanalyse wichtig, um die Varianz des Wortschatzes in verschiedenen Dokumenten zu bewerten.


### Tool: Voyant

![Voyant Tools](img/voyant_tools.png)


### Tool: Google Books N-Gram Viewer

Der [Google Books Ngram Viewer](https://books.google.com/ngrams/) ist ein leistungsstarkes Online-Tool, das es Nutzern ermöglicht, die Häufigkeit des Vorkommens bestimmter Wörter oder Phrasen in der Google-Büchersammlung über einen festgelegten Zeitraum zu analysieren. Im folgenden Beispiel sieht man bspw., wie häufig die Namen der Philosophen Martin Heidegger, Ludwig Wittgenstein und John Dewey zwischen 1900 und 2019 in deutschen Publikationen verwendet wurden:

<iframe name="ngram_chart" src="https://books.google.com/ngrams/interactive_chart?content=ludwig+wittgenstein,martin+heidegger,john+dewey&year_start=1950&year_end=2019&case_insensitive=on&corpus=de-2019&smoothing=3" width=1000 height=360 marginwidth=0 marginheight=0 hspace=0 vspace=0 frameborder=0 scrolling=no></iframe>

Das Tool kann für Geisteswissenschaftler sehr nützlich sein, weil es Einblicke in die Entwicklung und Verwendung bestimmter Begriffe oder Ideen im Laufe der Zeit bietet.

Hier ist ein kurzes Tutorial, das die Verwendung des [Google Books Ngram Viewer](https://books.google.com/ngrams/) anhand eines Beispiels erläutert:

**Schritt 1: Eingabe der Suchbegriffe** Überlegen Sie sich für Ihr philosophisches Beispiel geeignete Schlüsselbegriffe oder -phrasen. Nehmen wir an, Sie möchten die Entwicklung des philosophischen Begriffs "Existenzialismus" im 20. Jahrhundert analysieren. Geben Sie den Begriff "Existenzialismus" in das Suchfeld ein. Sie können auch verwandte Begriffe hinzufügen, um einen umfassenderen Kontext zu erhalten.

**Schritt 2: Festlegung der Parameter** Wählen Sie den gewünschten Zeitraum aus, den Sie analysieren möchten. Sie können den Zeitraum über die verfügbaren Optionen anpassen, z. B. von 1900 bis 2000. Achten Sie darauf, dass der gewählte Zeitraum für Ihre Analyse relevant ist.

**Schritt 3: Visualisierung und Analyse der Daten** Nachdem Sie die Suchbegriffe und den Zeitraum festgelegt haben, klicken Sie auf "Search". Der Ngram Viewer generiert dann ein Diagramm, das die Häufigkeit des Auftretens Ihrer Begriffe im ausgewählten Zeitraum anzeigt. Analysieren Sie die Grafik, um Trends, Spitzen oder Rückgänge in der Verwendung der Begriffe im Laufe der Zeit zu erkennen.

**Schritt 4: Interpretation der Ergebnisse** Basierend auf den angezeigten Daten interpretieren Sie die Ergebnisse und ziehen Sie Schlussfolgerungen über die Verbreitung und Relevanz des Begriffs "Existenzialismus" im Laufe des 20. Jahrhunderts. Beachten Sie dabei historische Ereignisse oder kulturelle Entwicklungen, die möglicherweise die Verwendung des Begriffs beeinflusst haben könnten.

**Schritt 5: Weiterführende Forschung** Verwenden Sie die gewonnenen Erkenntnisse als Ausgangspunkt für weitere Forschungen und Studien im Bereich der Philosophie. Vergleichen Sie beispielsweise die Verwendung von "Existenzialismus" mit anderen philosophischen Strömungen oder untersuchen Sie die Einflüsse bestimmter Philosophen auf die Verbreitung dieses Begriffs.

### Blücher: Distant Reading Ideen

**Bildet Kleingruppen!**

Entwickelt *Distant Reading* Ideen für die Vorlesung "Why and How We Study Philosophy" von Heinrich Blücher: Was interessiert euch? Wie könnten Voyant (oder der Google Books N-Gram Viewer) euch bei der Beantwortung der Fragen helfen?

### Zur nächsten Sitzung

Versucht Eure Idee für das *Distant Reading* von Heinrich Blücher als Kleingruppe umzusetzen. Entwickelt mindestens eine Visualisierung anhand der ihr Euer Forschungsinteresse/Eure Forschungsfrage beantworten könnt. 

## Sitzung am 21.11.